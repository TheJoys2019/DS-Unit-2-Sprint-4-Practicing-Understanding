{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Artin Sinani - (1 of 2) DS Unit 2 Sprint Challenge 4 Practicing Understanding.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheJoys2019/DS-Unit-2-Sprint-4-Practicing-Understanding/blob/master/Artin_Sinani_(1_of_2)_DS_Unit_2_Sprint_Challenge_4_Practicing_Understanding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjfltM6zTzaX",
        "colab_type": "text"
      },
      "source": [
        "_Lambda School Data Science Unit 2_\n",
        " \n",
        " # Sprint Challenge: Practicing & Understanding Predictive Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfmITgG8TzaY",
        "colab_type": "text"
      },
      "source": [
        "### Chicago Food Inspections\n",
        "\n",
        "For this Sprint Challenge, you'll use a dataset with information from inspections of restaurants and other food establishments in Chicago from January 2010 to March 2019. \n",
        "\n",
        "[See this PDF](https://data.cityofchicago.org/api/assets/BAD5301B-681A-4202-9D25-51B2CAE672FF) for descriptions of the data elements included in this dataset.\n",
        "\n",
        "According to [Chicago Department of Public Health â€” Food Protection Services](https://www.chicago.gov/city/en/depts/cdph/provdrs/healthy_restaurants/svcs/food-protection-services.html), \"Chicago is home to 16,000 food establishments like restaurants, grocery stores, bakeries, wholesalers, lunchrooms, mobile food vendors and more. Our business is food safety and sanitation with one goal, to prevent the spread of food-borne disease. We do this by inspecting food businesses, responding to complaints and food recalls.\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQd8wsakTzaZ",
        "colab_type": "text"
      },
      "source": [
        "#### Your challenge: Predict whether inspections failed\n",
        "\n",
        "The target is the `Fail` column.\n",
        "\n",
        "- When the food establishment failed the inspection, the target is `1`.\n",
        "- When the establishment passed, the target is `0`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2qyFRebTzaa",
        "colab_type": "text"
      },
      "source": [
        "#### Run this cell to load the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw3Nj6XlTzab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_url = 'https://drive.google.com/uc?export=download&id=13_tP9JpLcZHSPVpWcua4t2rY44K_s4H5'\n",
        "test_url  = 'https://drive.google.com/uc?export=download&id=1GkDHjsiGrzOXoF_xcYjdzBTSjOIi3g5a'\n",
        "\n",
        "train = pd.read_csv(train_url)\n",
        "test  = pd.read_csv(test_url)\n",
        "\n",
        "assert train.shape == (51916, 17)\n",
        "assert test.shape  == (17306, 17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn9C1SLgTzai",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OraQjUjoxByN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq9S4npjZ5E9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.drop(columns=[\"State\", \"Violations\"])\n",
        "test = test.drop(columns=[\"State\", \"Violations\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62gtj--oVfnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = train[\"Fail\"] == 1\n",
        "X_train = train.drop(columns=[\"Fail\"])\n",
        "\n",
        "y_test = test[\"Fail\"] == 1\n",
        "X_test = test.drop(columns=[\"Fail\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJiGSHSqV4JH",
        "colab_type": "code",
        "outputId": "d48ecd39-fb16-447b-ffb3-07234fa7350a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.9.0)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.24.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.20.3)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.16.3)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysQvMffjbgJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "preprocessor = make_pipeline(ce.OrdinalEncoder(), \n",
        "                             StandardScaler(), \n",
        "                             SimpleImputer())\n",
        "\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "\n",
        "X_train = pd.DataFrame(X_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsqQq8zzr1LV",
        "colab_type": "code",
        "outputId": "9cfedc65-3d0e-4c82-b48b-1c855d337a28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "scores = cross_validate(RandomForestClassifier(max_depth=5, n_estimators=100), \n",
        "                        X_train, \n",
        "                        y_train, \n",
        "                        scoring=\"roc_auc\",\n",
        "                        cv=3, \n",
        "                        return_train_score=True, \n",
        "                        return_estimator=True)\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.833824</td>\n",
              "      <td>0.131105</td>\n",
              "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
              "      <td>0.680477</td>\n",
              "      <td>0.703544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.834558</td>\n",
              "      <td>0.124022</td>\n",
              "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
              "      <td>0.682972</td>\n",
              "      <td>0.700089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.827459</td>\n",
              "      <td>0.130577</td>\n",
              "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
              "      <td>0.685247</td>\n",
              "      <td>0.698975</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time  ... test_score  train_score\n",
              "0  3.833824    0.131105  ...   0.680477     0.703544\n",
              "1  3.834558    0.124022  ...   0.682972     0.700089\n",
              "2  3.827459    0.130577  ...   0.685247     0.698975\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVLS-EK6t0Xp",
        "colab_type": "code",
        "outputId": "3e686692-09a2-4b96-c894-4abd233abd90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"ROC AUC Cross Validation Score:\", scores[\"test_score\"].mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC AUC Cross Validation Score: 0.6828985311803061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKbTFde1u4wW",
        "colab_type": "code",
        "outputId": "351c7681-fb74-46ed-fe4a-91e41037663b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1385
        }
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_distributions = {\n",
        "    \"n_estimators\": [100, 200, 300],\n",
        "    \"max_depth\": [4, 5, 6]\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    RandomForestClassifier(n_jobs=-1, random_state=42),\n",
        "    param_distributions=param_distributions, \n",
        "    n_iter=9, \n",
        "    cv=3, \n",
        "    scoring=\"roc_auc\", \n",
        "    verbose=10, \n",
        "    return_train_score=True)\n",
        "\n",
        "search.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
            "[CV] n_estimators=100, max_depth=4 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=100, max_depth=4, score=0.6730114085549883, total=   3.8s\n",
            "[CV] n_estimators=100, max_depth=4 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=100, max_depth=4, score=0.6759275876633415, total=   2.5s\n",
            "[CV] n_estimators=100, max_depth=4 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    6.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=100, max_depth=4, score=0.6763935085801869, total=   2.5s\n",
            "[CV] n_estimators=200, max_depth=4 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    9.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=200, max_depth=4, score=0.6741386816115323, total=   4.8s\n",
            "[CV] n_estimators=200, max_depth=4 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   14.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=200, max_depth=4, score=0.6763108374663085, total=   4.8s\n",
            "[CV] n_estimators=200, max_depth=4 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   19.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=200, max_depth=4, score=0.6801801904579438, total=   4.8s\n",
            "[CV] n_estimators=300, max_depth=4 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   25.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=300, max_depth=4, score=0.673164332924467, total=   7.2s\n",
            "[CV] n_estimators=300, max_depth=4 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   32.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=300, max_depth=4, score=0.6764348920346429, total=   7.3s\n",
            "[CV] n_estimators=300, max_depth=4 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   40.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=300, max_depth=4, score=0.6797566109458888, total=   7.2s\n",
            "[CV] n_estimators=100, max_depth=5 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   48.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=100, max_depth=5, score=0.6802493875711598, total=   3.0s\n",
            "[CV] n_estimators=100, max_depth=5 ...................................\n",
            "[CV]  n_estimators=100, max_depth=5, score=0.6862493893066617, total=   2.9s\n",
            "[CV] n_estimators=100, max_depth=5 ...................................\n",
            "[CV]  n_estimators=100, max_depth=5, score=0.688271848887689, total=   3.0s\n",
            "[CV] n_estimators=200, max_depth=5 ...................................\n",
            "[CV]  n_estimators=200, max_depth=5, score=0.6822535117578675, total=   5.9s\n",
            "[CV] n_estimators=200, max_depth=5 ...................................\n",
            "[CV]  n_estimators=200, max_depth=5, score=0.6863484413712623, total=   5.8s\n",
            "[CV] n_estimators=200, max_depth=5 ...................................\n",
            "[CV]  n_estimators=200, max_depth=5, score=0.6886092302869061, total=   5.7s\n",
            "[CV] n_estimators=300, max_depth=5 ...................................\n",
            "[CV]  n_estimators=300, max_depth=5, score=0.6825687288993277, total=   8.8s\n",
            "[CV] n_estimators=300, max_depth=5 ...................................\n",
            "[CV]  n_estimators=300, max_depth=5, score=0.6861578005460317, total=   8.6s\n",
            "[CV] n_estimators=300, max_depth=5 ...................................\n",
            "[CV]  n_estimators=300, max_depth=5, score=0.6887988783272445, total=   8.4s\n",
            "[CV] n_estimators=100, max_depth=6 ...................................\n",
            "[CV]  n_estimators=100, max_depth=6, score=0.6883079985957843, total=   3.4s\n",
            "[CV] n_estimators=100, max_depth=6 ...................................\n",
            "[CV]  n_estimators=100, max_depth=6, score=0.690292819291378, total=   3.4s\n",
            "[CV] n_estimators=100, max_depth=6 ...................................\n",
            "[CV]  n_estimators=100, max_depth=6, score=0.6917186151521617, total=   3.4s\n",
            "[CV] n_estimators=200, max_depth=6 ...................................\n",
            "[CV]  n_estimators=200, max_depth=6, score=0.6893230162494767, total=   6.7s\n",
            "[CV] n_estimators=200, max_depth=6 ...................................\n",
            "[CV]  n_estimators=200, max_depth=6, score=0.6913622663363188, total=   6.5s\n",
            "[CV] n_estimators=200, max_depth=6 ...................................\n",
            "[CV]  n_estimators=200, max_depth=6, score=0.6924795412288762, total=   6.7s\n",
            "[CV] n_estimators=300, max_depth=6 ...................................\n",
            "[CV]  n_estimators=300, max_depth=6, score=0.6884520769643868, total=   9.9s\n",
            "[CV] n_estimators=300, max_depth=6 ...................................\n",
            "[CV]  n_estimators=300, max_depth=6, score=0.6906838546179738, total=   9.9s\n",
            "[CV] n_estimators=300, max_depth=6 ...................................\n",
            "[CV]  n_estimators=300, max_depth=6, score=0.6917056479880866, total=   9.9s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  2.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
              "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
              "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
              "          fit_params=None, iid='warn', n_iter=9, n_jobs=None,\n",
              "          param_distributions={'n_estimators': [100, 200, 300], 'max_depth': [4, 5, 6]},\n",
              "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "          return_train_score=True, scoring='roc_auc', verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWCdk64Gp5ng",
        "colab_type": "code",
        "outputId": "5a120f56-e543-41d5-9721-9502dc645ef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Cross Validation ROC_AUC:', search.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross Validation ROC_AUC: 0.6910549079114173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVgEDAycqG-M",
        "colab_type": "code",
        "outputId": "40eb95c3-a64f-4d0f-befb-4c14834d4577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "best = search.best_estimator_\n",
        "y_pred_proba = best.predict_proba(X_test.values)[:,1]\n",
        "print('Test ROC AUC:', roc_auc_score(y_test, y_pred_proba))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test ROC AUC: 0.6963621275115393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQkpo-K4rsuX",
        "colab_type": "text"
      },
      "source": [
        "### Part 1: Preprocessing\n",
        "\n",
        "You may choose which features you want to use, and whether/how you will preprocess them. If you use categorical features, you may use any tools and techniques for encoding. (Pandas, category_encoders, sklearn.preprocessing, or any other library.)\n",
        "\n",
        "_To earn a score of 3 for this part, find and explain leakage. The dataset has a feature that will give you an ROC AUC score > 0.90 if you process and use the feature. Find the leakage and explain why the feature shouldn't be used in a real-world model to predict the results of future inspections._\n",
        "\n",
        "### Part 2: Modeling\n",
        "\n",
        "**Fit a model** with the train set. (You may use scikit-learn, xgboost, or any other library.) **Use cross-validation** to **do hyperparameter optimization**, and **estimate your ROC AUC** validation score.\n",
        "\n",
        "Use your model to **predict probabilities** for the test set. **Get an ROC AUC test score >= 0.60.**\n",
        "\n",
        "_To earn a score of 3 for this part, get an ROC AUC test score >= 0.70 (without using the feature with leakage)._\n",
        "\n",
        "\n",
        "### Part 3: Visualization\n",
        "\n",
        "Make one visualization for model interpretation. (You may use any libraries.) Choose one of these types:\n",
        "\n",
        "- Feature Importances\n",
        "- Permutation Importances\n",
        "- Partial Dependence Plot\n",
        "- Shapley Values\n",
        "\n",
        "_To earn a score of 3 for this part, make at least two of these visualization types._\n",
        "\n",
        "### Part 4: Gradient Descent\n",
        "\n",
        "Answer both of these two questions:\n",
        "\n",
        "- What does Gradient Descent seek to minimize?\n",
        "- What is the \"Learning Rate\" and what is its function?\n",
        "\n",
        "One sentence is sufficient for each.\n",
        "\n",
        "_To earn a score of 3 for this part, go above and beyond. Show depth of understanding and mastery of intuition in your answers._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBaqL70Urtqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}